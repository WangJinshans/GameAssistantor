



map分段锁:
type FragmentMap struct {
	dataMap        map[string]interface{}
	sync.RWMutex // 读写锁, 保护dataMap
}


type ConcurrentHashMap []*FragmentMap

func fnv32(key string) uint32 {
   // 著名的fnv哈希函数, 由 Glenn Fowler、Landon Curt Noll和 Kiem-Phong Vo 创建
   hash := uint32(2166136261)
   const prime32 = uint32(16777619)
   keyLength := len(key)
   for i := 0; i < keyLength; i++ {
      hash *= prime32
      hash ^= uint32(key[i])
   }
   return hash
}


func (m ConcurrentHashMap) GetShardMap(key string) *SharedMap {
	return m[uint(fnv32(key))%uint(ShardCount)]
}

// Set 添加 key-value
func (m ConcurrentHashMap) Set(key string, value interface{}) {
   // Get map shard.
   shard := m.GetShardMap(key)
   shard.Lock()
   shard.items[key] = value
   shard.Unlock()
}


// Get 返回指定key的value值
func (m ConcurrentHashMap) Get(key string) (interface{}, bool) {
   shard := m.GetShardMap(key)
   shard.RLock()
   val, ok := shard.items[key]
   shard.RUnlock()
   return val, ok
}


// Remove 删除一个元素
func (m ConcurrentHashMap) Remove(key string) {
   // Try to get shard.
   shard := m.GetShardMap(key)
   shard.Lock()
   delete(shard.items, key)
   shard.Unlock()
}


// Has 判断元素是否存在
func (m ConcurrentHashMap) Has(key string) bool {
   // Get shard
   shard := m.GetShardMap(key)
   shard.RLock()
   // See if element is within shard.
   _, ok := shard.items[key]
   shard.RUnlock()
   return ok
}

// Count 统计元素总数
func (m ConcurrentHashMap) Count() int {
   count := 0
   for i := 0; i < ShardCount; i++ {
      shard := m[i]
      shard.RLock()
      count += len(shard.items)
      shard.RUnlock()
   }
   return count
}

参考: https://www.cnblogs.com/yinbiao/p/15884420.html




1. 支付倒计时: 延时队列, RabbitMQ, Redis Zset 截止时间作为Score
2. 分布式锁: Redis, 当前线程设置随机值, 执行成功后需要读取值并判断是否是当前线程设置的值, 防止业务逻辑执行时间过长导致key过期, 另外的节点设置相同的key, 同时当前逻辑执行成功后删掉其他节点设置的key
3. 朋友圈(关注列表Feed流): 推模式与拉模式, 判断用户是否活跃, 是否大V, 分页可采用last_id来做, https://cloud.tencent.com/developer/article/1744756, (总页数可用redis, incr新增, 同时新增定时任务晚上从db同步到redis)
4. 推荐: 基于推荐算法实现的Feed流
4. 好友关系: Redis集合, BitMap
5. 直播服务: 
    1. 绑定主播推流Id(监听流异常), 直播间: map[user_id][tcp_id], user_info[user_id][info], 聊天室添加人员, 剔除人员, 发言, 禁言均可通过操作info
    2. 点赞, 刷礼物, 发言, 抽奖, 抽象GroupChat, 多节点分段遍历下发, SendToGroup -> Kafka/Channel -> GroupSend, 超高并发的情况下用Kafka可能会导致大量的流量消耗
    3. 直播间消息发送服务扩容, 直播间开辟chat_room_server_list, add, remove, 扩展多个节点, GroupSend退化为tcp推送到扩展节点, 按照规则分片推送可降低消息延迟

6. 用户Tcp的连接关系不一定需要维护到Redis, 也可根据部分字段(如user_id)做一致性hash算法得到, 前提是Tcp建立的时候也可根据该规则转发连接, 否则只能维护对应关系
7. 敏感词
8. 秒杀方案: 
      前端优化 --> cdn --> ip限流 --> 接口限流(hystric,幂等限制) --> Redis减扣(decr, lua脚本(库存逻辑判断)) --> Kafka --> 手动commit # 通过另外新建消费者组查看当前消费者组的情况
9. 分布式一致性方案:
   1. 分布式事务(事务拆分, 2阶段提交, 强一致性)
   2. MQ解耦, 手动ACK确认(最终一致性)
10.DTM分布式事务
11.Mysql 事务机制:
   设置事务的超时时间(timeout)如果一个事务在指定的时间内没有提交或回滚,那么数据库会自动终止该事务,并释放其占用的资源
   使用死锁检测(deadlock detection),如果数据库发现两个或多个事务相互等待对方释放锁,形成了死锁,那么数据库会选择一个或多个事务作为牺牲者,强制终止它们,并释放其占用的资源
   使用垃圾回收(garbage collection),如果数据库发现有一些未提交的事务已经被客户端断开连接或者崩溃，那么数据库会自动回滚这些事务，并清理其占用的资源
   
12.延时双删(弱一致,最大问题在更新数据库的时候, 如果多个线程同时更新, 但是由于网络原因出现请求乱序, 最后更新到Redis的数据将会不一致)):
   服务节点删除 redis 主库数据
   服务节点修改 mysql 主库数据
   服务节点使得当前业务处理 等待一段时间，等 redis 和 mysql 主从节点数据同步成功
   服务节点从 redis 主库删除数据
   当前或其它服务节点读取 redis 从库数据，发现 redis 从库没有数据，从 mysql 从库读取数据，并写入 redis 主库


9. Elastic Search原理: 
      倒排索引: 


10.大型分布式系统, 付款成功, 但是配送数据写入失败, 是否存在必须要写入成功但是写入失败的情况, 是否存在多个系统协同全部满足条件才进行下一步的系统
   
   多服务多条件 ==> 协同管理器 ==> 处理结果
   服务A  \           / 服务A
   服务B --  处理器 --   服务B
   服务C  /           \ 服务C

   table_name sql











